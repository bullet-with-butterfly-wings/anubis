{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['proAnubis_240811_2240.raw', 'proAnubis_240810_2240.raw', 'proAnubis_240810_2040.raw', 'proAnubis_240810_1840.raw', 'proAnubis_240810_1640.raw', 'proAnubis_240810_1440.raw', 'proAnubis_240810_1240.raw', 'proAnubis_240810_1040.raw', 'proAnubis_240810_0840.raw', 'proAnubis_240810_0640.raw', 'proAnubis_240810_0440.raw', 'proAnubis_240810_0240.raw', 'proAnubis_240810_0040.raw']\n",
      "['C://Users//jony//Programming//Python//Anubis//anubis//data//reset//proAnubis_240810_0040.raw']\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import  os\n",
    "import glob\n",
    "\n",
    "# Add the directories to the sys.path\n",
    "dir_path = \"C://Users//jony//Programming//Python//Anubis//anubis//\" # insert your directory path\n",
    "sys.path.append(dir_path + \"Osiris//processing//python\")\n",
    "sys.path.append(dir_path + \"Osiris//monitoring//python\")\n",
    "sys.path.append(dir_path + \"tools\")\n",
    "\n",
    "import Analysis_tools as ATools\n",
    "import proAnubis_Analysis_Tools\n",
    "import Reconstruction_tools as RTools\n",
    "import rawEventBuilder\n",
    "import mplhep as hep\n",
    "import Timing_tools as TTools\n",
    "import rawFileReader\n",
    "import Visual_tools as VTools\n",
    "import datetime\n",
    "\n",
    "hep.style.use([hep.style.ATLAS])\n",
    "\n",
    "# Specify the directory\n",
    "data_list = sorted([f for f in os.listdir(\"data//reset\") if os.path.isfile(os.path.join(\"data//reset\", f))], reverse=True) ##all files in data directory sorted from the newest to the oldest\n",
    "print(data_list)\n",
    "file_path = [dir_path+\"//data//\"+\"proAnubis_240731_0217.raw\"] #\n",
    "file_path = list(map(lambda p: dir_path+\"data//reset//\"+p, data_list))[-1:] # insert your file\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing proAnubis_240810_0040:  59%|█████▉    | 5878/10000 [08:58<06:17, 10.92Events/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad Block Read\n",
      "Exception: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking proAnubis_240810_0040:  96%|█████████▌| 5878/6125 [00:00<00:00, 95500.86Events/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pause: 240\n",
      "Event time: 6.599951\n",
      "Chunk size: 0:00:00\n",
      "Pause: 653\n",
      "Event time: 24.022565\n",
      "Chunk size: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(rawFileReader) # Reload fReader\n",
    "importlib.reload(proAnubis_Analysis_Tools)\n",
    "importlib.reload(ATools)\n",
    "importlib.reload(VTools)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "interval = 100 # Set your monitoring chunck size\n",
    "order = [(0,1), (1,2), (2,3), (3,4)] # Order what you want to align\n",
    "actual_mets = {}\n",
    "last_time = None\n",
    "for file in file_path:\n",
    "    max_process_event_chunk = 10_000 # End the loop early\n",
    "    file_name = file.split(\"//\")[-1][:-4] #must be a right file\n",
    "    fReader = rawFileReader.fileReader(file) # reload in the classs object\n",
    "    processedEvents = 0 # Initialisation\n",
    "    mets = []\n",
    "    binsx = []\n",
    "    initial_event_chunk = fReader.get_aligned_events(order=order, interval=interval) # get the initial event chunk\n",
    "    originTime = min([event_chunk[0].tdcEvents[tdc].time for tdc in range(5) if event_chunk[0].tdcEvents[tdc].time])\n",
    "    chunks = []\n",
    "    with tqdm(total=max_process_event_chunk, desc=f\"Processing {file_name}\", unit='Events') as pbar:\n",
    "        while processedEvents < max_process_event_chunk:\n",
    "            processedEvents += 1\n",
    "            try:\n",
    "                event_chunk = fReader.get_aligned_events(order=order, interval=interval) # get the aligned events\n",
    "                if not event_chunk:\n",
    "                    #print(\"Misaligned:\", processedEvents)\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                print(\"Exception:\", e)\n",
    "                max_process_event_chunk = processedEvents\n",
    "                break\n",
    "            chunks.append(event_chunk)\n",
    "            pbar.update(1)\n",
    "\n",
    "    chunks = sorted(chunks, key= lambda c: (min([c[0].tdcEvents[tdc].time for tdc in range(5) if c[0].tdcEvents[tdc].time])-originTime).total_seconds())\n",
    "\n",
    "    with tqdm(total=max_process_event_chunk, desc=f\"Checking {file_name}\", unit='Events') as pbar:\n",
    "        for processedEvents, event_chunk in enumerate(chunks):\n",
    "            event_time = min([event_chunk[0].tdcEvents[tdc].time for tdc in range(5) if event_chunk[0].tdcEvents[tdc].time])\n",
    "            if last_time:\n",
    "                if (event_time - last_time).total_seconds() > 1:\n",
    "                    print(\"Pause:\", processedEvents-1)\n",
    "                    print(\"Event time:\", (last_time - originTime).total_seconds())\n",
    "                    print(\"Length:\", (event_time - last_time).total_seconds())\n",
    "                    last_event_time = min([event_chunk[-1].tdcEvents[tdc].time for tdc in range(5) if event_chunk[-1].tdcEvents[tdc].time])\n",
    "                    first_event_time = min([event_chunk[0].tdcEvents[tdc].time for tdc in range(5) if event_chunk[0].tdcEvents[tdc].time])\n",
    "                    print(\"Chunk size:\",last_event_time - first_event_time)\n",
    "            else:\n",
    "                originTime = event_time \n",
    "            \n",
    "            binsx.append((event_time - originTime).total_seconds())\n",
    "            last_time = event_time \n",
    "            pbar.update(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jony\\AppData\\Local\\Temp\\ipykernel_2368\\2257912587.py:10: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.plot(sorted(check_t), check_ch)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(binsx, mets)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Counts vs Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
