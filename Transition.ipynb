{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy hist matplotlib mplhep pandas plotly scipy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C://Users//jony//Programming//Python//Anubis//anubis//data//reset//proAnubis_240811_2240.raw']\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import  os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "# Add the directories to the sys.path\n",
    "dir_path = \"C://Users//jony//Programming//Python//Anubis//anubis//\" # insert your directory path\n",
    "sys.path.append(dir_path + \"Osiris//processing//python\")\n",
    "sys.path.append(dir_path + \"tools\")\n",
    "\n",
    "import rawEventBuilder\n",
    "import Analysis_tools as ATools\n",
    "import proAnubis_Analysis_Tools\n",
    "import Reconstruction_tools as RTools\n",
    "import mplhep as hep\n",
    "import Timing_tools as TTools\n",
    "import rawFileReader\n",
    "import Visual_tools as VTools\n",
    "hep.style.use([hep.style.ATLAS])\n",
    "\n",
    "# Specify the directory\n",
    "data_list = sorted([f for f in os.listdir(\"data\") if os.path.isfile(os.path.join(\"data\", f))], reverse=True) ##all files in data directory sorted from the newest to the oldest\n",
    "\n",
    "file_path = list(map(lambda p: dir_path+\"//data\"+p, data_list))[:1] #\n",
    "file_path = ['C://Users//jony//Programming//Python//Anubis//anubis//data//reset//proAnubis_240811_2240.raw']\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_alignment(mets, order, max_process_event_chunk, file_name):\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    for idx, item in enumerate(order):\n",
    "        met = mets[idx]\n",
    "        i, j = item\n",
    "        binsx = [x for x in range(len(met))]\n",
    "        ax.plot(binsx, met, label=f'TDC{i} and TDC{j}, offset 0')\n",
    "    ax.set_xlim(0, max_process_event_chunk)\n",
    "    ax.set_ylim(-1, 40)\n",
    "    ax.legend()\n",
    "    ax.set_title(f'Alignment graph {file_name}')\n",
    "    ax.set_ylabel('Average $\\sqrt{d\\eta^2+d\\phi^2}$')\n",
    "    ax.set_xlabel('Processed Event chunks')\n",
    "    plt.savefig(f\"output//transition//alignment_{file_name}.png\")\n",
    "\n",
    "def plot_bvg(tdc_mets, max_process_event_chunk, file_name):\n",
    "    colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    for tdc in range(5):\n",
    "        met = tdc_mets[tdc]\n",
    "        binsx = [x*26.5 for x in range(len(met))]\n",
    "        ax.plot(binsx,met, label = f'tdc {tdc}', color = colors[tdc])\n",
    "\n",
    "    ax.set_xlim(0,max_process_event_chunk)\n",
    "    ax.legend()\n",
    "    ax.set_title(f'TDC monitoring metric {file_name}')\n",
    "    ax.set_ylabel('bad time behavior / nominal time behavior')\n",
    "    ax.set_xlabel('processed event chunks')\n",
    "    plt.savefig(f\"output//transition//tdc_monitoring{file_name}.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Events proAnubis_240811_2240: 100%|██████████| 3000/3000 [01:19<00:00, 37.84Events/s]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(rawFileReader) # Reload fReader\n",
    "importlib.reload(proAnubis_Analysis_Tools)\n",
    "importlib.reload(ATools)\n",
    "importlib.reload(VTools)\n",
    "importlib.reload(rawEventBuilder)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "interval = 100 # Set your monitoring chunck size\n",
    "order = [[0,1], [1,2], [2,3], [3,4]] # Order what you want to align\n",
    "    \n",
    "for file in file_path:\n",
    "    max_process_event_chunk = 3_000 # End the loop early\n",
    "    fReader = rawFileReader.fileReader(file) # load in the classs object\n",
    "    #fReader.skip_events(2000*100) # Skip the first event\n",
    "    processedEvents = 0 # Initialisation\n",
    "    noiseStart = 0\n",
    "    firstNoise = False\n",
    "    initial_event_chunk = fReader.get_aligned_events(order=order, interval=interval)\n",
    "    originTime = max([initial_event_chunk[0].tdcEvents[tdc].time for tdc in range(5) if initial_event_chunk[0].tdcEvents[tdc].time])\n",
    "    last_reset = 0\n",
    "    mets = [[] for tdc in range(5)]\n",
    "    mets_off = [[] for tdc in range(5)]\n",
    "    file_name = file.split(\"//\")[-1][:-4]\n",
    "    tdc_mets = [[] for tdc in range(5)]\n",
    "    Tot_TDC_info = [[] for tdc in range(5)]\n",
    "    chunks = []\n",
    "    bad_chunks = 0\n",
    "    with tqdm(total=max_process_event_chunk, desc=f\"Processing Events {file_name}\", unit='Events') as pbar:\n",
    "        while processedEvents < max_process_event_chunk:\n",
    "            processedEvents += 1\n",
    "            try:\n",
    "                event_chunk, tdc_met, TDC_info = fReader.get_aligned_events(order=order, interval=interval, extract_tdc_mets = True) # get the aligned events\n",
    "            except Exception as e:\n",
    "                print(\"Exception:\", e)\n",
    "                max_process_event_chunk = processedEvents\n",
    "                break\n",
    "\n",
    "            event_time = max([event_chunk[0].tdcEvents[tdc].time for tdc in range(5) if event_chunk[0].tdcEvents[tdc].time])\n",
    "            \n",
    "            if last_reset:\n",
    "                if (event_time - last_reset).total_seconds() > 60:\n",
    "                    last_reset = event_time\n",
    "                    fReader.evtBuilder = rawEventBuilder.eventBuilder()\n",
    "            else:\n",
    "                last_reset = event_time\n",
    "                originTime = event_time\n",
    "                \n",
    "            [tdc_mets[i].append(tdc_met[i]) for i in range(5) if tdc_met[i] != 0]\n",
    "            [Tot_TDC_info[i].extend(TDC_info[i]) for i in range(5) if TDC_info[i]]\n",
    "            for idx, (i, j) in enumerate(order):\n",
    "                x, y, l, m = ATools.find_tdc_alignment_metric(i, j) # determining which RPCs to use for aignment metric\n",
    "                alignMet = ATools.calcAvgAlign(event_chunk, 0, x, y, l, m, i, j, processedEvents) # determine the alignment metric\n",
    "                #alignMet_off = ATools.calcAvgAlign(event_chunk, 15, x, y, l, m, i, j, processedEvents) # determine the alignment metric\n",
    "                \n",
    "                #mets_off[idx].append(alignMet_off) # write to memory\n",
    "                mets[idx].append(alignMet) # write to memory\n",
    "                if alignMet > 40 and not firstNoise:\n",
    "                    for tdc in range(5):\n",
    "                        if event_chunk[0].tdcEvents[tdc].time != 0:\n",
    "                            noiseTime = event_chunk[0].tdcEvents[tdc].time\n",
    "                            break\n",
    "                    if noiseTime == 0:\n",
    "                        print(\"No hits in the event???\")\n",
    "                    startTime =  noiseTime - originTime\n",
    "                    print(startTime)\n",
    "                    noiseStart = processedEvents*interval\n",
    "                    print(noiseStart)\n",
    "                    firstNoise = True\n",
    "\n",
    "            pbar.update(1)\n",
    "    \n",
    "    #plot_alignment(mets_off, order, max_process_event_chunk, file_name+\"_off\")\n",
    "    plot_alignment(mets, order, max_process_event_chunk, file_name+\"HUGE_mini\")\n",
    "    #plot_bvg(tdc_mets, max_process_event_chunk, file_name+\"fuck\")\n",
    "    plot_bvg(tdc_mets, max_process_event_chunk, file_name+\"HUGE_mini\")\n",
    "    \n",
    "    if noiseStart:\n",
    "        TTools.plot_tdc_error_channels_custom_ranges(Tot_TDC_info, [(0, noiseStart), (noiseStart, max_process_event_chunk*interval)], tdcs_to_plot=None, output_pdf=f'output//transition//TDC_channel_perEv_{file_name}.pdf')\n",
    "    else:\n",
    "        TTools.plot_tdc_error_channels_custom_ranges(Tot_TDC_info, [(0, max_process_event_chunk*interval)], tdcs_to_plot=None, output_pdf=f'output//transition//TDC_channel_perEv_{file_name}.pdf')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m#plot_bvg(tdc_mets, max_process_event_chunk, file_name+\"fuck\")\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#plot_bvg(tdc_mets, max_process_event_chunk, file_name+\"HUGE\")\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m noiseStart:\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mTTools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_tdc_error_channels_custom_ranges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTot_TDC_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoiseStart\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoiseStart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_process_event_chunk\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtdcs_to_plot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_pdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput//transition//TDC_channel_perEv_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     TTools\u001b[38;5;241m.\u001b[39mplot_tdc_error_channels_custom_ranges(Tot_TDC_info, [(\u001b[38;5;241m0\u001b[39m, max_process_event_chunk\u001b[38;5;241m*\u001b[39minterval)], tdcs_to_plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_pdf\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput//transition//TDC_channel_perEv_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\/Users//jony//Programming//Python//Anubis//anubis//tools\\Timing_tools.py:292\u001b[0m, in \u001b[0;36mplot_tdc_error_channels_custom_ranges\u001b[1;34m(TDC_error_time, ranges, tdcs_to_plot, output_pdf)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m range_start \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m+\u001b[39mevent_count \u001b[38;5;241m<\u001b[39m range_end:\n\u001b[0;32m    291\u001b[0m     channel \u001b[38;5;241m=\u001b[39m (hit_word \u001b[38;5;241m>>\u001b[39m \u001b[38;5;241m24\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0x7f\u001b[39m\n\u001b[1;32m--> 292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m300\u001b[39m \u001b[38;5;241m>\u001b[39m hit_time \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m100\u001b[39m:\n\u001b[0;32m    293\u001b[0m         good_channels[channel] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plot_alignment(mets[:100_000], order, 100_000, file_name+\"HUGEshort\")\n",
    "    #plot_bvg(tdc_mets, max_process_event_chunk, file_name+\"fuck\")\n",
    "#plot_bvg(tdc_mets, max_process_event_chunk, file_name+\"HUGE\")\n",
    "    \n",
    "if noiseStart:\n",
    "    TTools.plot_tdc_error_channels_custom_ranges(Tot_TDC_info, [(0, noiseStart), (noiseStart, max_process_event_chunk*interval)], tdcs_to_plot=None, output_pdf=f'output//transition//TDC_channel_perEv_{file_name}.pdf')\n",
    "else:\n",
    "    TTools.plot_tdc_error_channels_custom_ranges(Tot_TDC_info, [(0, max_process_event_chunk*interval)], tdcs_to_plot=None, output_pdf=f'output//transition//TDC_channel_perEv_{file_name}.pdf')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "with open('alg_huge.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(mets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTools.plot_tdc_error_times_custom_ranges(Tot_TDC_info, [(0, noiseStart), (noiseStart, max_process_event_chunk*interval)], output_pdf=f'output//transition//Time_Hit_{file_name}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "#print([mets[i].index(max(mets[i])) for i in range(4)])\n",
    "import Visual_tools as VTools\n",
    "importlib.reload(VTools)\n",
    "\n",
    "\n",
    "#for chunk in chunks:\n",
    "#    print(VTools.metric_possible(chunk, 2,3))\n",
    "x = [i for i in range(max_process_event_chunk)]\n",
    "tot_good1 = [0 for chunk in range(max_process_event_chunk)]\n",
    "tot_good2 = [0 for chunk in range(max_process_event_chunk)]\n",
    "tot_poss = [0 for chunk in range(max_process_event_chunk)]\n",
    "print(len(x))\n",
    "for i, chunk in enumerate(chunks):\n",
    "    tot_poss[i], tot_good1[i], tot_good2[i] = VTools.metric_possible(chunk, 2, 3)\n",
    "\n",
    "plt.plot(x, tot_good1, color='blue')\n",
    "plt.plot(x, tot_good2, color='red')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x, tot_poss)\n",
    "plt.show()\n",
    "#VTools.all_hits(chunks[31], 2, 3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46958\n",
      "50442\n",
      "40026\n",
      "44355\n",
      "30623\n",
      "5\n",
      "46958\n",
      "50442\n",
      "40026\n",
      "44355\n",
      "30623\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(TTools)\n",
    "odlozim = Tot_TDC_info.copy()\n",
    "for tdc in range(5):\n",
    "    print(len(Tot_TDC_info[tdc]))\n",
    "    Tot_TDC_info[tdc] = Tot_TDC_info[tdc][:noiseStart]\n",
    "TTools.plot_tdc_error_channels(Tot_TDC_info, tdcs_to_plot=[2,3])\n",
    "\n",
    "Tot_TDC_info = odlozim.copy()\n",
    "print(len(odlozim))\n",
    "for tdc in range(5):\n",
    "    print(len(Tot_TDC_info[tdc]))\n",
    "    Tot_TDC_info[tdc] = Tot_TDC_info[tdc][noiseStart:]\n",
    "TTools.plot_tdc_error_channels(Tot_TDC_info, tdcs_to_plot=[2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(VTools)\n",
    "counts = [[] for tdc in range(5)]\n",
    "for chunk in chunks:\n",
    "    count = VTools.abs_count(chunk)\n",
    "    for tdc in range(5):\n",
    "        counts[tdc].append(count[tdc])\n",
    "\n",
    "#plot it\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "for tdc in range(5):\n",
    "    ax.plot(x, counts[tdc], label = f'TDC {tdc}')\n",
    "ax.legend()\n",
    "ax.set_title(f'Counts per TDC')\n",
    "ax.set_ylabel('Counts')\n",
    "ax.set_xlabel('Processed Event chunks')\n",
    "plt.savefig(f\"output//transition//TDC_counts.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "for idx, item in enumerate(order):\n",
    "    met = mets[idx]\n",
    "    i, j = item\n",
    "    binsx = [x for x in range(len(met))]\n",
    "    ax.plot(binsx, met, label=f'TDC{i} and TDC{j}, offset 0')\n",
    "ax.set_xlim(0, max_process_event_chunk)\n",
    "ax.set_ylim(-1, 40)\n",
    "ax.legend()\n",
    "\n",
    "ax.set_title(f'Alignment graph {file_name}')\n",
    "ax.set_ylabel('Average $\\sqrt{d\\eta^2+d\\phi^2}$')\n",
    "ax.set_xlabel('Processed Event chunks')\n",
    "plt.savefig(f\"output//transition//alignment_graph{file_name}.png\")\n",
    "\n",
    "colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "for tdc in range(5):\n",
    "    met = tdc_mets[tdc]\n",
    "    binsx = [x*26.5 for x in range(len(met))]\n",
    "    ax.plot(binsx,met, label = f'tdc {tdc}', color = colors[tdc])\n",
    "\n",
    "ax.set_xlim(0,max_process_event_chunk)\n",
    "ax.legend()\n",
    "ax.set_title(f'TDC monitoring metric {file_name}')\n",
    "ax.set_ylabel('bad time behavior / nominal time behavior')\n",
    "ax.set_xlabel('processed event chunks')\n",
    "plt.savefig(f\"output//transition//tdc_monitoring{file_name}.png\")\n",
    "plt.close()\n",
    "\n",
    "#TTools.plot_tdc_error_channels_custom_ranges(Tot_TDC_info, [(0, noiseStart), (noiseStart, max_process_event_chunk*interval)], tdcs_to_plot=None, output_pdf=f'output//transition//TDC_channel{file_name}.pdf')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
